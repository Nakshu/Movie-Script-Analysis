{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ddf382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twilight (2008) - Twilight (2008) - User Reviews - IMDb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 73/73 [00:03<00:00, 20.42it/s]\n",
      "100%|█████████████████████████████████████████| 250/250 [00:03<00:00, 69.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scrapy.selector import Selector\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Passing the movie review url and using selenium to open a browser and visit that URL.\n",
    "\n",
    "browser = webdriver.Chrome('chromedriver.exe')\n",
    "url = 'https://www.imdb.com/title/tt1099212/reviews?ref_=tt_urv'\n",
    "time.sleep(1)\n",
    "browser.get(url)\n",
    "time.sleep(1)\n",
    "print(browser.title)\n",
    "time.sleep(1)\n",
    "body = browser.find_element(By.CSS_SELECTOR, 'body')\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "time.sleep(1)\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "time.sleep(1)\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "# Extracting the review count\n",
    "\n",
    "s = Selector(text = browser.page_source)\n",
    "review_counts = s.css('.lister .header span::text').extract_first().replace(',','').split(' ')[0]\n",
    "review_pages = int(int(review_counts)/25)\n",
    "\n",
    "# Loading all the reviews present in each page\n",
    "\n",
    "for i in tqdm(range(review_pages)):\n",
    "    try:\n",
    "        css_selector = 'load-more-trigger'\n",
    "        browser.find_element(By.ID, css_selector).click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Extracting the reviews from the HTML \n",
    "\n",
    "reviews = browser.find_elements(By.CSS_SELECTOR, 'div.review-container')\n",
    "first_review = reviews[0]\n",
    "s2 = Selector(text = first_review.get_attribute('innerHTML'))\n",
    "rating = s2.css('.rating-other-user-rating span::text').extract_first().strip()\n",
    "\n",
    "# for loop to extract the rating, review, author and, review title for all the reviews\n",
    "\n",
    "rating_list = []\n",
    "review_date_list = []\n",
    "review_title_list = []\n",
    "author_list = []\n",
    "review_list = []\n",
    "review_url_list = []\n",
    "error_url_list = []\n",
    "error_msg_list = []\n",
    "reviews = browser.find_elements(By.CSS_SELECTOR, 'div.review-container')\n",
    "\n",
    "for d in tqdm(reviews):\n",
    "    try:\n",
    "        s2 = Selector(text = d.get_attribute('innerHTML'))\n",
    "        try:\n",
    "            rating = s2.css('.rating-other-user-rating span::text').extract_first()\n",
    "        except:\n",
    "            rating = np.NaN\n",
    "        try:\n",
    "            review = s2.css('.text.show-more__control::text').extract_first()\n",
    "        except:\n",
    "            review = np.NaN\n",
    "        try:\n",
    "            review_date = s2.css('.review-date::text').extract_first()\n",
    "        except:\n",
    "            review_date = np.NaN    \n",
    "        try:\n",
    "            author = s2.css('.display-name-link a::text').extract_first()\n",
    "        except:\n",
    "            author = np.NaN    \n",
    "        try:\n",
    "            review_title = s2.css('a.title::text').extract_first()\n",
    "        except:\n",
    "            review_title = np.NaN\n",
    "        try:\n",
    "            review_url = s2.css('a.title::attr(href)').extract_first()\n",
    "        except:\n",
    "            review_url = np.NaN\n",
    "        rating_list.append(rating)\n",
    "        review_date_list.append(review_date)\n",
    "        review_title_list.append(review_title)\n",
    "        author_list.append(author)\n",
    "        review_list.append(review)\n",
    "        review_url_list.append(review_url)\n",
    "    except Exception as e:\n",
    "        error_url_list.append(url)\n",
    "        error_msg_list.append(e)\n",
    "review_df = pd.DataFrame({\n",
    "    'Review_Date':review_date_list,\n",
    "    'Author':author_list,\n",
    "    'Rating':rating_list,\n",
    "    'Review_Title':review_title_list,\n",
    "    'Review':review_list,\n",
    "    'Review_Url':review_url\n",
    "    })\n",
    "# Saving the review into a csv\n",
    "review_df.to_csv('/Users/pr472/Desktop/Masters/Fall-22/Data Acquisition and Pre-Processing/Final_Project/imdb_review1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b810e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
